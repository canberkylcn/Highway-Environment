env_id: "highway-v0"
# Render mode kesinlikle null olmalı! / Render mode must be null!
render_mode: null 

env_params:
  observation:
    type: "Kinematics"
    vehicles_count: 10       # Yakındaki 10 aracı gör (sağ/sol/ön)
    features: ["presence", "x", "y", "vx", "vy"]  # Konum ve hız bilgisi
    absolute: false          # Göreceli konum → sağ/sol/ön algılaması
    order: "sorted"          # En yakın araçlar önce
    normalize: true          # Değerleri normalize et (öğrenme kolaylığı)
  action:
    type: "DiscreteMetaAction"
  duration: 80               # Episode süresi
  
  # SİMÜLASYON AYARLARI
  simulation_frequency: 15   # Fizik simülasyonu frekansı
  policy_frequency: 2        # Karar frekansı (daha sık = daha hızlı tepki)
  
  # TRAFİK AYARLARI
  lanes_count: 4             # 4 şeritli yol
  vehicles_count: 30         # Orta yoğunlukta trafik (sollama fırsatı için)
  vehicles_density: 1.2      # Araç yoğunluğu
  
  # ===== ÖDÜL AYARLARI =====
  # Toplam ödül = collision + speed + right_lane + lane_change
  
  # 1) ÇARPIŞMA → Kesinlikle yapma
  collision_reward: -3.0     # Dengeli ceza (öğrenmeyi bozmaz)
  
  # 2) HIZ → Önü boşken hızlı git
  high_speed_reward: 0.6     # Hızlı gitmek ödül
  reward_speed_range: [20, 35]  # Bu aralıkta tam puan
  
  # 3) ŞERİT → Sollama serbest ama zikzak yapma
  lane_change_reward: -0.1   # Küçük ceza → gereksiz şerit değişimini engeller
  right_lane_reward: 0.0     # Şerit tercihi yok
  
  # 4) DİĞER
  normalize_reward: true
  offroad_terminal: false
  
  # Araç davranışları
  other_vehicles_type: "highway_env.vehicle.behavior.IDMVehicle"


agent_params:
  algorithm: "PPO"
  total_timesteps: 200000
  save_path: "models/highway_ppo_best_model"
  tensorboard_log: "logs/tensorboard/"
  checkpoint_freq: 100000
  
  model_params:
    learning_rate: 0.0005
    n_steps: 2048
    batch_size: 64
    n_epochs: 10
    gamma: 0.95            # Uzun vadeli düşün (sollama planlaması)
    gae_lambda: 0.95
    clip_range: 0.2
    ent_coef: 0.01
    verbose: 1